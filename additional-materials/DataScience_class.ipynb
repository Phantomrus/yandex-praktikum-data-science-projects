{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScience:\n",
    "\n",
    "    def path_to_files(self, path, link):\n",
    "        Path('datasets').mkdir(parents=True, exist_ok=True)\n",
    "        def get_file(file_name, url):\n",
    "            if not os.path.exists(file_name):\n",
    "                print(file_name, 'файл не найден, будет загружен из сети')\n",
    "                _ = urllib.request.urlretrieve(url, file_name)\n",
    "        urls = {\n",
    "            'dataset': (path, link)\n",
    "        }\n",
    "        [get_file(*urls[k]) for k in urls]\n",
    "        data = pd.read_csv(urls['dataset'][0])\n",
    "        return data\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "    def corr_diagram(self, x):\n",
    "        plt.figure(figsize=(12, 10), dpi=80)\n",
    "        sns.heatmap(x.corr(), xticklabels=x.corr().columns, yticklabels=x.corr().columns, cmap='RdYlGn', center=0,\n",
    "                    annot=True)\n",
    "        plt.title('Диаграмма корреляции', fontsize=22)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        plt.show()\n",
    "\n",
    "    def highlight_max(self, data, color='#00FF00'):\n",
    "        '''\n",
    "        highlight the maximum in a Series or DataFrame\n",
    "        '''\n",
    "        attr = 'background-color: {}'.format(color)\n",
    "        # remove % and cast to float\n",
    "        data = data.replace('%', '', regex=True).astype(float)\n",
    "        data[data == 1] = None\n",
    "        if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "            is_max = (data == data.abs().max()) & (data != 1)\n",
    "            return [attr if v else '' for v in is_max]\n",
    "        else:  # from .apply(axis=None)\n",
    "            is_max = (data == data.abs().max()) & (data != 1)\n",
    "            return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                                index=data.index, columns=data.columns)\n",
    "\n",
    "    def highlight_sorted_corr(self, data, color='#00FF00'):\n",
    "        '''\n",
    "        highlight the maximum in a Series or DataFrame\n",
    "        '''\n",
    "        attr = 'background-color: {}'.format(color)\n",
    "        # remove % and cast to float\n",
    "        data = data.replace('%', '', regex=True).astype(float)\n",
    "        data[data == 1] = None\n",
    "        if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "            is_max = (data > 0.1) & (data != 1)\n",
    "            return [attr if v else '' for v in is_max]\n",
    "        else:  # from .apply(axis=None)\n",
    "            is_max = (data == data.abs().max()) & (data != 1)\n",
    "            return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                                index=data.index, columns=data.columns)\n",
    "\n",
    "    def lineplot(self, x_data, y_data, x_label=\"\", y_label=\"\", title=\"\"):\n",
    "        # Создаем объект - график\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Задаем параметры для линии: ширину (lw), цвет и прозрачность (alpha)\n",
    "        ax.plot(x_data, y_data, lw=2, color='#539caf', alpha=1)\n",
    "\n",
    "        # Даем имена осям и заголовок для графика\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "    def double_lineplot(self, x_data_1, y_data_1, x_data_2, y_data_2, x_label=\"\", y_label=\"\", title=\"\", label_one=\"\",\n",
    "                        label_two=\"\"):\n",
    "        # Создаем объект - график\n",
    "        _, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "        # Задаем параметры для линии: ширину (lw), цвет и прозрачность (alpha)\n",
    "        ax.plot(x_data_1, y_data_1, lw=2, color='#6400e4', alpha=1, label=label_one)\n",
    "        ax.plot(x_data_2, y_data_2, lw=2, color='#ffc740', alpha=1, label=label_two)\n",
    "\n",
    "        # Даем имена осям и заголовок для графика\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        ax.legend(loc='best')\n",
    "\n",
    "    def hexbin(self, data, x, y):\n",
    "        data.plot(x=x, y=y, kind='hexbin', gridsize=20, figsize=(15, 10), sharex=False, grid=True)\n",
    "\n",
    "    def bar_plotter(self, data):\n",
    "        data.plot.bar(rot=0, figsize=(16, 5))\n",
    "\n",
    "    def categorical_counter_plot(self, data, column, x='', y=''):\n",
    "        if x == '' or y == '':\n",
    "            plt.rcParams[\"figure.figsize\"] = (15, 10)\n",
    "        else:\n",
    "            plt.rcParams[\"figure.figsize\"] = (x, y)\n",
    "\n",
    "        order = data[column].value_counts().index\n",
    "\n",
    "        ax = sns.countplot(data[column], order=order)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), fontsize=11)\n",
    "        plt.xticks(rotation=90)\n",
    "\n",
    "    def sns_scatterplot(self, data, x=\"\", y=\"\", hue=\"\", size=\"\", palette=\"\"):\n",
    "\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        f, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "        if palette == True:\n",
    "            sns.scatterplot(ax=ax, x=x, y=y, palette=\"ch:r=-.2,d=.3_r\",\n",
    "                            hue=hue, size=size, sizes=(1, 200), linewidth=0, data=data)\n",
    "        else:\n",
    "            sns.scatterplot(ax=ax, x=x, y=y,\n",
    "                            hue=hue, size=size,\n",
    "                            sizes=(1, 200), linewidth=0, data=data)\n",
    "\n",
    "    def sns_catplot(self, data, x=\"\", y=\"\", hue=\"\"):\n",
    "        sns.set(style='whitegrid')\n",
    "        sns.catplot(x=x, y=y, hue=hue, kind='bar', errwidth=0,\n",
    "                    data=data, height=5, aspect=3)\n",
    "\n",
    "    def sns_factorplot(self, data, x='', hue=''):\n",
    "        sns.axes_style('white')\n",
    "        g = sns.factorplot(\"exited\", data=df, aspect=1, kind='count',\n",
    "                           hue='hascrcard')\n",
    "\n",
    "    def squared_ratio(self, df, grouper, title=''):\n",
    "        df = df.groupby(grouper).size().reset_index(name='counts')\n",
    "        labels = df.apply(lambda x: str(x[0]) + \"\\n (\" + str(x[1]) + \")\", axis=1)\n",
    "        sizes = df['counts'].values.tolist()\n",
    "        colors = [plt.cm.Spectral(i / float(len(labels))) for i in range(len(labels))]\n",
    "        plt.figure(figsize=(10, 6), dpi=80)\n",
    "        squarify.plot(sizes=sizes, label=labels, color=colors, alpha=.8)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    def sorted_corr(self, data, attr):\n",
    "        correlated = pd.DataFrame(data.corr()[attr].sort_values(ascending=False))\n",
    "\n",
    "        return correlated\n",
    "\n",
    "\n",
    "    def pr_curve(self, model, features_valid, target_valid):\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        precision, recall, thresholds = precision_recall_curve(target_valid, probabilities_valid[:, 1])\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.step(recall, precision, where='post')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('Кривая Precision-Recall')\n",
    "        plt.show()\n",
    "\n",
    "    def roc_curve(self, model, features_valid, target_valid):\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(target_valid, probabilities_one_valid)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC-кривая')\n",
    "        plt.show()\n",
    "\n",
    "    def metrics_plot(self, model, features_valid, target_valid):\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        precision, recall, thresholds = precision_recall_curve(target_valid, probabilities_valid[:, 1])\n",
    "        fpr, tpr, thresholds = roc_curve(target_valid, probabilities_valid[:, 1])\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "        # fig, ax = plt.subplots(ncols=3)\n",
    "        # fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "        sns.lineplot(recall, precision, drawstyle='steps-post', ax=ax[0])\n",
    "        ax[0].set_xlabel('Recall')\n",
    "        ax[0].set_ylabel('Precision')\n",
    "        ax[0].set_ylim([0.0, 1.05])\n",
    "        ax[0].set_xlim([0.0, 1.0])\n",
    "        ax[0].set_title('Кривая Precision-Recall')\n",
    "        sns.lineplot(fpr, tpr, ax=ax[1])\n",
    "        ax[1].plot([0, 1], [0, 1], linestyle='--')\n",
    "        ax[1].set_xlim(0, 1)\n",
    "        ax[1].set_ylim(0, 1)\n",
    "        ax[1].set_xlabel('False Positive Rate')\n",
    "        ax[1].set_ylabel('True Positive Rate')\n",
    "        ax[1].set_title('ROC-кривая')\n",
    "\n",
    "    def auc_roc(self, model, features_valid, target_valid):\n",
    "        probabilities_valid = model.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        auc_roc = roc_auc_score(target_valid, probabilities_one_valid)\n",
    "\n",
    "        return auc_roc\n",
    "\n",
    "    def upsample(self, features, target, repeat):\n",
    "        features_zeros = features[target == 0]\n",
    "        features_ones = features[target == 1]\n",
    "        target_zeros = target[target == 0]\n",
    "        target_ones = target[target == 1]\n",
    "        features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "        features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=42)\n",
    "\n",
    "        return features_upsampled, target_upsampled\n",
    "\n",
    "    def downsample(self, features, target, fraction):\n",
    "        features_zeros = features[target == 0]\n",
    "        features_ones = features[target == 1]\n",
    "        target_zeros = target[target == 0]\n",
    "        target_ones = target[target == 1]\n",
    "        features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "        target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "        features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=42)\n",
    "\n",
    "        return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "    def df_split(self, data, features_drop, target, test_size, random_state):\n",
    "        feature = data.drop(features_drop, axis=1)\n",
    "        target = data[target]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(feature, target, test_size=test_size,\n",
    "                                                            random_state=random_state)\n",
    "        return x_train, x_test, y_train, y_test\n",
    "\n",
    "    def grid_search(self, model, param_grid, cv, x, y):\n",
    "        grid_model = GridSearchCV(model, param_grid=param_grid, cv=cv, verbose=1, n_jobs=-1)\n",
    "        grid_model.fit(x, y)\n",
    "        best_estimator = grid_model.best_estimator_\n",
    "\n",
    "        return best_estimator\n",
    "\n",
    "    def clean_dataset(self, df):\n",
    "        assert isinstance(df, pd.DataFrme), \"df needs to be a pd.DataFrame\"\n",
    "        df.dropna(inplace=True)\n",
    "        indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "\n",
    "        return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "    def missing_zero_values_table(self, df):\n",
    "        zero_val = (df == 0.00).astype(int).sum(axis=0)\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n",
    "        mz_table = mz_table.rename(\n",
    "            columns={0: 'Zero Values', 1: 'Missing Values', 2: '% of Total Values'})\n",
    "        mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n",
    "        mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n",
    "        mz_table['Data Type'] = df.dtypes\n",
    "        mz_table = mz_table[\n",
    "            mz_table.iloc[:, 1] != 0].sort_values(\n",
    "            '% of Total Values', ascending=False).round(1)\n",
    "        print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"\n",
    "                                                                                                       \"There are \" + str(\n",
    "            mz_table.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "\n",
    "        return mz_table\n",
    "\n",
    "\n",
    "        \n",
    "    def fill_with_mode(self, column, column1, column2):\n",
    "        df[column] = df.groupby([column1, column2])[column].transform(lambda x: x.fillna((x.mode()[0] if not x.mode().empty else \"Empty\")))\n",
    "        \n",
    "    \n",
    "    def rmse(self,predictions, targets): \n",
    "        return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "    \n",
    "    \n",
    "    def plot_feature_importance(self,importance,names,model_type):\n",
    "\n",
    "        feature_importance = np.array(importance)\n",
    "        feature_names = np.array(names)\n",
    "\n",
    "        #Create a DataFrame using a Dictionary\n",
    "        data={'feature_names':feature_names,'feature_importance':feature_importance}\n",
    "        fi_df = pd.DataFrame(data)\n",
    "\n",
    "        #Sort the DataFrame in order decreasing feature importance\n",
    "        fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n",
    "\n",
    "        #Define size of bar plot\n",
    "        plt.figure(figsize=(10,8))\n",
    "        #Plot Searborn bar chart\n",
    "        sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n",
    "        #Add chart labels\n",
    "        plt.title(model_type + 'FEATURE IMPORTANCE')\n",
    "        plt.xlabel('FEATURE IMPORTANCE')\n",
    "        plt.ylabel('FEATURE NAMES')\n",
    "        \n",
    "    def fit(self,train_features, train_actuals):\n",
    "        \"\"\"\n",
    "        fits the list of models to the training data, thereby obtaining in each \n",
    "        case an evaluation score after GridSearchCV cross-validation\n",
    "        \"\"\"\n",
    "        for name in models.keys():\n",
    "            est = models[name]\n",
    "            est_params = params[name]\n",
    "            gscv = GridSearchCV(estimator=est, param_grid=est_params, cv=5)\n",
    "            start = time.time()\n",
    "            gscv.fit(train_features, train_actuals)\n",
    "            end = time.time()\n",
    "            total_time = end - start            \n",
    "            time_list.append(total_time)\n",
    "            predictions = gscv.predict(X_test)\n",
    "            rmse_list.append(ds.rmse(predictions,y_test))\n",
    "            print(\"best parameters are: {}\".format(gscv.best_estimator_))\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CatBoostRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ad002990c47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m models = {\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;34m'CatBoostRegressor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCatBoostRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'LGBMRegressor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'XGBRegressor'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CatBoostRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'CatBoostRegressor': CatBoostRegressor(),\n",
    "    'LGBMRegressor': lgb.LGBMRegressor(),\n",
    "    'XGBRegressor': xgboost.XGBRegressor()\n",
    "}\n",
    "\n",
    "# the optimisation parameters for each of the above models\n",
    "params = {\n",
    "    'CatBoostRegressor':{\n",
    "          'loss_function':['RMSE'],\n",
    "          'iterations':[500],\n",
    "          'learning_rate':[0.5], \n",
    "          'random_state':[17]\n",
    "    },        \n",
    "\n",
    "    'LGBMRegressor': {\n",
    "        'task': ['train'],\n",
    "        'boosting_type':['gbdt'],\n",
    "        'objective':['regression'],\n",
    "        'metric':['rmse'],\n",
    "        'learning_rate':[0.5],\n",
    "        'num_iterations':[500]\n",
    "        },\n",
    "    \n",
    "    \n",
    "    'XGBRegressor': {\n",
    "        \n",
    "        'min_child_weight': [10],\n",
    "        'gamma': [5],\n",
    "        'subsample': [1.0],\n",
    "        'colsample_bytree': [1.0],\n",
    "        'max_depth': [5]\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
